doc_id: bio_short
tags: [bio, summary]
source_items: [identity, timeline, awards, publications]
updated: 2025-11-07
---

Prasanth Sasikumar is an XR and wearable AI researcher whose work bridges multimodal sensing and human–computer interaction. As a Research Fellow at the National University of Singapore, he designs adaptive VR/AR systems that use physiological signals (EEG/ECG/GSR/HRV), eye gaze, and hand/pose cues to model cognitive load, affect, and comfort—enabling more natural remote collaboration and training.

His research has been published at top venues including CHI, IEEE VR, ISMAR, SIGGRAPH Asia, and Frontiers in Virtual Reality. Recent projects include co-creating a large-scale VR motion sickness dataset with industry partners, studying how shared physiological cues improve joint performance in VR assembly tasks, and developing real-time AR accessibility tools for deaf and hard-of-hearing learners. He also explores emotion recognition from subtle motor signals in immersive environments and cross-reality telepresence systems.

Previously, Prasanth held research roles at the University of Auckland and Massey University, and industry roles in XR development and full‑stack engineering. He holds a PhD in Bioengineering (University of Auckland), a Master’s in Human Interface Technology (University of Canterbury), and a Bachelor’s in Computer Science Engineering (University of Kerala).
